{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pprint\n",
    "import textwrap\n",
    "import json\n",
    "\n",
    "from math import sqrt, log\n",
    "from hashlib import sha1\n",
    "from graphviz import Digraph\n",
    "from credentials import ID, SECRET\n",
    "from praw.models import MoreComments as more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=ID,\n",
    "    client_secret=SECRET,\n",
    "    user_agent=\"The Rhetor Project\"\n",
    ")\n",
    "\n",
    "post = reddit.submission(id=\"17llow9\")\n",
    "topic = post.title[5:]\n",
    "desc = post.selftext\n",
    "comments = post.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# (Inadequate) sentiment analysis\n",
    "def sentiment(reply):\n",
    "\tsents = sent_tokenize(reply)[0]\n",
    "\tSIA = SentimentIntensityAnalyzer()\n",
    "\treturn SIA.polarity_scores(sents)[\"compound\"]\n",
    "\n",
    "def clean(raw):\n",
    "\tparsed = soup(raw)\n",
    "\n",
    "\t# Remove all <blockquotes>\n",
    "\tfor b in parsed.find_all('blockquote'):\n",
    "\t\tb.extract()\n",
    "\t\n",
    "\treturn parsed.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = [0, 0, 0]\n",
    "vis = Digraph(format='png')\n",
    "\n",
    "def process(parent, comment):\n",
    "    cur = {\n",
    "        \"content\": clean(comment.body_html),\n",
    "        \"id\": comment.id,\n",
    "        \"name\": sha1(f\"{comment.author.name}\".encode()).hexdigest(),\n",
    "        \"depth\": comment.depth+1,\n",
    "        \"votes\": 0 if comment.score_hidden else abs(comment.score),\n",
    "        \"ranked\": True if comment.author_flair_text else False,\n",
    "        \"spicy\": bool(comment.controversiality),\n",
    "        \"score\": 0,\n",
    "        \"threadScore\": 0,\n",
    "        \"below\": False, # max # layers below\n",
    "        \"agree\": None,\n",
    "        \"replies\": []\n",
    "    }\n",
    "    \n",
    "    # Prune\n",
    "    if not cur[\"spicy\"] and cur[\"votes\"] < 3:\n",
    "        pruned[0] += 1; return\n",
    "    # if len(cur[\"content\"]) < 50:\n",
    "    wordCount = len(word_tokenize(cur[\"content\"]))\n",
    "    if wordCount < 15: pruned[1] += 1; return\n",
    "\n",
    "    maxBelow = 0\n",
    "    for r in comment.replies:\n",
    "        if isinstance(r, more) or not r.author: continue\n",
    "        replyThread = process(cur[\"id\"], r)  # Recurse\n",
    "        if replyThread: \n",
    "            cur[\"replies\"].append(replyThread)\n",
    "            cur[\"threadScore\"] += replyThread[\"score\"]\n",
    "            if replyThread[\"below\"] is not False:\n",
    "                if replyThread[\"below\"] > maxBelow: maxBelow = replyThread[\"below\"]\n",
    "\n",
    "\n",
    "    # Depth/below calc\n",
    "    if not cur[\"replies\"]:\n",
    "        cur[\"below\"] = 0 # False -> 0: hit a leaf\n",
    "        if cur[\"depth\"] < 3: \n",
    "            pruned[2] += 1; return\n",
    "    else:\n",
    "        cur[\"below\"] = maxBelow + 1\n",
    "\n",
    "    # Score calculation\n",
    "    S = 1.2 if cur[\"spicy\"] else 1   # boost controvserial comment scores\n",
    "    R = 1.4 if cur[\"ranked\"] else 1  # favor \"seasoned\" commenters\n",
    "    L = sqrt((wordCount-10)/5)       # encourage longer comments\n",
    "    # D = sqrt(cur[\"depth\"])         # boost deep comment scores\n",
    "    B = (cur[\"below\"]+.5)/2           # devalue no/shallow subthreads\n",
    "\n",
    "    cur[\"score\"] = S*R*L*B*cur[\"votes\"]\n",
    "    cur[\"threadScore\"] += cur[\"score\"]\n",
    "\n",
    "\n",
    "    # (Dis)agreement\n",
    "    # sen = sentiment(cur[\"content\"])\n",
    "    # cur[\"agree\"] = False if sen < -0.7 else (True if sen > 0.9 else None)\n",
    "\n",
    "    vis.node(cur[\"id\"], label=cur[\"content\"], shape='box') # Add node\n",
    "    vis.node(cur[\"id\"], label=f\"{cur['threadScore']:.2f} ({cur['score']:.2f})\\n{S:.1f}, {R:.1f}, {L:.1f}, {B:.1f}\\n{textwrap.fill(cur['content'], 25)[:100]}{'...' if len(cur['content'])>50 else ''}\", shape='box')\n",
    "\n",
    "    edge_color = 'black' if cur[\"agree\"] is None else ('green' if cur[\"agree\"] else 'red')\n",
    "    edge_label = '?' if cur[\"agree\"] is None else ('Agree' if cur[\"agree\"] else 'Disagree')\n",
    "    \n",
    "    # Create edge \n",
    "    vis.edge(parent, cur[\"id\"], label=edge_label, color=edge_color, fontcolor=edge_color)\n",
    "\n",
    "    return cur \n",
    "\n",
    "\n",
    "def traverse(comments):\n",
    "    threads = []\n",
    "    vis.node(\"root\", label=topic, shape='box')  # Add root\n",
    "    for c in comments: # Each TLC\n",
    "        if isinstance(c, more) or c.stickied: continue\n",
    "        if c.author is None: continue\n",
    "        thread = process(\"root\", c)\n",
    "        if thread: \n",
    "            threads.append(thread)\n",
    "            # print(f\"{thread['threadScore']:0.2f}\")\n",
    "    return threads\n",
    "\n",
    "tree = {\n",
    "    \"root\": {\n",
    "        \"content\": topic,\n",
    "        \"replies\": traverse(comments)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned comments:\n",
      "\t40 with low engagement\n",
      "\t27 were too short\n",
      "\t49 from shallow threads\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tree.png'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4, sort_dicts=False)\n",
    "# pp.pprint(tree)\n",
    "json.dump(tree, open(\"tree.json\", \"w\"), indent=4, sort_keys=False)\n",
    "\n",
    "print(\n",
    "\t\"Pruned comments:\\n\"\n",
    "\tf\"\\t{pruned[0]} with low engagement\\n\"\n",
    "\tf\"\\t{pruned[1]} were too short\\n\"\n",
    "\tf\"\\t{pruned[2]} from shallow threads\\n\"\n",
    ")\n",
    "\n",
    "vis.render('tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
